"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é –∞—Ç—Ä–∏–±—É—Ü–∏–∏ —Ä—É–∫–æ–ø–∏—Å–µ–π
"""

import os
import shutil
from pathlib import Path
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

def create_sample_dataset_structure(base_path="data"):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    print(f"–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ –ø–∞–ø–∫–µ '{base_path}'...")
    
    # –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ø–∞–ø–∫—É
    Path(base_path).mkdir(exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è –∞–≤—Ç–æ—Ä–æ–≤
    authors = ["author1", "author2", "author3", "author4", "author5"]
    
    for author in authors:
        author_path = Path(base_path) / author
        author_path.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º README —Ñ–∞–π–ª –≤ –∫–∞–∂–¥–æ–π –ø–∞–ø–∫–µ
        readme_path = author_path / "README.txt"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(f"–ü–∞–ø–∫–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä—É–∫–æ–ø–∏—Å–µ–π –∞–≤—Ç–æ—Ä–∞: {author}\n")
            f.write("–ü–æ–º–µ—Å—Ç–∏—Ç–µ —Å—é–¥–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–∞—Ö: .jpg, .jpeg, .png\n")
            f.write("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 50-100 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –∞–≤—Ç–æ—Ä–∞\n")
    
    print(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ–∑–¥–∞–Ω–∞:")
    print(f"   {base_path}/")
    for author in authors:
        print(f"   ‚îú‚îÄ‚îÄ {author}/")
        print(f"   ‚îÇ   ‚îî‚îÄ‚îÄ README.txt")
    print()
    print("üìù –¢–µ–ø–µ—Ä—å –ø–æ–º–µ—Å—Ç–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–µ–π –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏")

def validate_dataset(data_dir):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ –ø–∞–ø–∫–µ '{data_dir}'...")
    
    if not os.path.exists(data_dir):
        print(f"‚ùå –ü–∞–ø–∫–∞ '{data_dir}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return False
    
    authors = []
    total_images = 0
    
    for item in os.listdir(data_dir):
        item_path = os.path.join(data_dir, item)
        if os.path.isdir(item_path):
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ –∞–≤—Ç–æ—Ä–∞
            images = [f for f in os.listdir(item_path) 
                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            authors.append({
                'name': item,
                'count': len(images),
                'path': item_path
            })
            total_images += len(images)
    
    if not authors:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫ —Å –∞–≤—Ç–æ—Ä–∞–º–∏")
        return False
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"   üë• –ê–≤—Ç–æ—Ä–æ–≤: {len(authors)}")
    print(f"   üñºÔ∏è  –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    print()
    
    print("üìã –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
    for author in authors:
        status = "‚úÖ" if author['count'] >= 50 else "‚ö†Ô∏è" if author['count'] >= 20 else "‚ùå"
        print(f"   {status} {author['name']}: {author['count']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    print()
    if total_images < 100:
        print("‚ö†Ô∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")
    else:
        print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    
    return True

def preprocess_image_for_analysis(image_path, output_path=None):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # –£–ª—É—á—à–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç
    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    enhanced = cv2.merge([l, a, b])
    image = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)
    
    # –£–±–∏—Ä–∞–µ–º —à—É–º
    image = cv2.medianBlur(image, 3)
    
    # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    processed = cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB)
    
    if output_path:
        cv2.imwrite(output_path, cv2.cvtColor(processed, cv2.COLOR_RGB2BGR))
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    
    return processed

def visualize_preprocessing(image_path):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    original = cv2.imread(image_path)
    original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
    processed = preprocess_image_for_analysis(image_path)
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    
    axes[0].imshow(original)
    axes[0].set_title('–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
    axes[0].axis('off')
    
    axes[1].imshow(processed)
    axes[1].set_title('–ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏')
    axes[1].axis('off')
    
    plt.tight_layout()
    plt.show()

def batch_preprocess_dataset(input_dir, output_dir):
    """–ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    print(f"–ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    print(f"–í—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {input_dir}")
    print(f"–í—ã—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {output_dir}")
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É
    Path(output_dir).mkdir(exist_ok=True)
    
    processed_count = 0
    
    for author_folder in os.listdir(input_dir):
        author_path = os.path.join(input_dir, author_folder)
        if not os.path.isdir(author_path):
            continue
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∞–≤—Ç–æ—Ä–∞ –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        output_author_path = os.path.join(output_dir, author_folder)
        Path(output_author_path).mkdir(exist_ok=True)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∞
        for image_file in os.listdir(author_path):
            if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                input_path = os.path.join(author_path, image_file)
                output_path = os.path.join(output_author_path, image_file)
                
                try:
                    preprocess_image_for_analysis(input_path, output_path)
                    processed_count += 1
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {input_path}: {e}")
    
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {processed_count}")

def analyze_dataset_quality(data_dir):
    """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    print("–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    image_sizes = []
    total_images = 0
    
    for author_folder in os.listdir(data_dir):
        author_path = os.path.join(data_dir, author_folder)
        if not os.path.isdir(author_path):
            continue
        
        for image_file in os.listdir(author_path):
            if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_path = os.path.join(author_path, image_file)
                try:
                    with Image.open(image_path) as img:
                        image_sizes.append(img.size)
                        total_images += 1
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {image_path}: {e}")
    
    if not image_sizes:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤
    widths = [size[0] for size in image_sizes]
    heights = [size[1] for size in image_sizes]
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
    print(f"   üñºÔ∏è  –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    print(f"   üìè –®–∏—Ä–∏–Ω–∞: {min(widths)} - {max(widths)} (—Å—Ä–µ–¥–Ω–µ–µ: {np.mean(widths):.0f})")
    print(f"   üìê –í—ã—Å–æ—Ç–∞: {min(heights)} - {max(heights)} (—Å—Ä–µ–¥–Ω–µ–µ: {np.mean(heights):.0f})")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    min_size = min(min(widths), min(heights))
    if min_size < 224:
        print(f"‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–µ–Ω—å—à–µ 224px ({min_size}px)")
        print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é")
    else:
        print("‚úÖ –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

def create_training_script():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    
    script_content = '''"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∞—Ç—Ä–∏–±—É—Ü–∏–∏ —Ä—É–∫–æ–ø–∏—Å–µ–π
"""

from handwriting_attribution import HandwritingAttribution
from utils import validate_dataset

def main():
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    if not validate_dataset("data/"):
        print("‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º. –ò—Å–ø—Ä–∞–≤—å—Ç–µ –∏—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º.")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    num_authors = 3  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ—Ä–æ–≤
    model = HandwritingAttribution(num_authors)
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è {num_authors} –∞–≤—Ç–æ—Ä–æ–≤...")
    
    # –û–±—É—á–µ–Ω–∏–µ
    try:
        model.train(
            data_dir="data/",
            epochs=50,
            batch_size=16,
            learning_rate=0.001
        )
        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")

if __name__ == "__main__":
    main()
'''
    
    with open("train_model.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print("‚úÖ –°–æ–∑–¥–∞–Ω —Å–∫—Ä–∏–ø—Ç train_model.py –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")

if __name__ == "__main__":
    print("=== –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∞—Ç—Ä–∏–±—É—Ü–∏–∏ —Ä—É–∫–æ–ø–∏—Å–µ–π ===\n")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞
    create_sample_dataset_structure()
    
    # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
    create_training_script()
    
    print("\nüéâ –£—Ç–∏–ª–∏—Ç—ã –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    print("üìÅ –°–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print("üìù –°–æ–∑–¥–∞–Ω —Å–∫—Ä–∏–ø—Ç train_model.py")
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("   1. –ü–æ–º–µ—Å—Ç–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–µ–π –≤ –ø–∞–ø–∫–∏ –∞–≤—Ç–æ—Ä–æ–≤")
    print("   2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python train_model.py")
